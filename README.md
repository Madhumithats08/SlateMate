# SlateMate

## ðŸ§  Project Overview

This project was developed as part of the SlateMate AI/ML technical assignment. The objective was to analyze real-world social media metadata and classify each post as:

- âœ… **Safe** â€” educational, motivational, or clean content  
- âš ï¸ **Neutral** â€” emotionally charged or uncertain content  
- âŒ **Unsafe** â€” toxic, harmful, offensive, or suggestive content

The system supports automated moderation by generating a labeled output and a structured summary report.

---

## ðŸ“‚ Files Included

| File Name               | Description |
|-------------------------|-------------|
| `SlateMate_Classifier.ipynb` | Jupyter Notebook containing full pipeline |
| `moderated_feed.csv`    | Final dataset with classifications |
| `report_summary.md`     | Summary report with insights and flagged examples |
| `README.md`             | This file |
| `social_feed_metadata.csv` | Input dataset |
| `label_distribution.png` | Label distribution chart |

---

## ðŸ”§ Tools & Technologies Used

- **Detoxify** (transformer-based model for toxicity detection)
- **TextBlob** (for sentiment & emotion analysis)
- **Pandas** and **Seaborn** (for data processing & visualization)
- **Custom Keyword List** for detecting unsafe terms
- **Simulated Google Vision API** (to mimic image content moderation)
- â€œSince actual image files were not available, we simulated the behavior of Google Vision APIâ€™s SafeSearch detection using random label generation. This allows the classifier to incorporate visual safety concerns such as adult or violent content in a realistic manner.â€

---

##  How the Classifier Works

1. **Text Cleaning & Preprocessing**
2. **Toxicity Scoring** with Detoxify (range: 0â€“1)
3. **Keyword Flagging** for terms like "kill", "hate", "nsfw"
4. **Emotion Detection** using TextBlob polarity scores
5. **Simulated Image Flagging** (to demonstrate multimodal moderation)
6. **Label Assignment**:
   - `toxicity > 0.7` or flagged â†’ **Unsafe**
   - `toxicity 0.3â€“0.7` or sad tone â†’ **Neutral**
   - otherwise â†’ **Safe**
7. **Reason Column** for moderation transparency

---

##  How to Run This Project

### ðŸ–¥ï¸ 1. Clone or download the repository
```bash
git clone https://github.com/Madhumithats08/SlateMate.git
cd slatemate-classifier
````

### ðŸ“¦ 2. Install required packages

Make sure you have Python 3.7+ and run:

```bash
pip install -r requirements.txt
```

If not using a `requirements.txt`, manually install:

```bash
pip install detoxify textblob pandas seaborn torch transformers
```

### â–¶ï¸ 3. Run the notebook

```bash
jupyter notebook
```

Open `SlateMate_Classifier.ipynb` and run all cells.

---

## ðŸ“ˆ Sample Output

* ðŸ“„ `moderated_feed.csv` with labeled posts
* ðŸ“ `report_summary.md` for insights
* ðŸ“Š Optional `label_distribution.png` chart

---

> **Note**: This project was developed and tested in Google Colab for ease of reproducibility. All output files can be regenerated by running the notebook from top to bottom.

## ðŸ“… Date

15th May 2025


